{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Convert the raw data from FormKeep (csv) and GetForm (xls) services\n",
    "and save them into `raw-data-processed.csv`.\n",
    "\n",
    "FormKeep files have been slightly modified manually to use\n",
    "the same columns as GetForm files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from pandas import Series, DataFrame\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# excel (xls, xlsx) reading also requires\n",
    "# pip install xlrd\n",
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE patterns for files to load from\n",
    "LOAD_FROM = [\"raw_data/devanagari/*.csv\",\n",
    "             \"raw_data/devanagari/*.xls\",\n",
    "             \"raw_data/devanagari/*.xlsx\",\n",
    "             \"raw_data/cyrillic/*.csv\",\n",
    "             \"raw_data/cyrillic/*.xls\",\n",
    "             \"raw_data/cyrillic/*.xlsx\",\n",
    "             \"raw_data/latin_and_cyrillic/*.csv\",\n",
    "             \"raw_data/latin_and_cyrillic/*.xls\",\n",
    "             \"raw_data/latin_and_cyrillic/*.xlsx\",\n",
    "             ]\n",
    "# folder to save the CSVs to\n",
    "SAVE_TO = \"csv/\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Language normalisation\n",
    "\n",
    "PUNCTUATION = [\"(\", \"+\", \")\", \"/\", \"&\", \" \", \".\", \";\", \" - \", u\"।\"]\n",
    "\n",
    "ANDS = [u\"and\", u\"ий\", u\"и\", u\"і\", u\"й\", u\"та\", u\"and\", u\"&\", u\"और\", u\"व\", u\"तथा\", \"aur\"]\n",
    "\n",
    "LANGS_CORRECTIONS_SEARCH = OrderedDict([\n",
    "    (u\"most of cyrillic based.\", \"\"),\n",
    "    (u\"(can read english more fluently than hindi)\", \"\"),\n",
    "    (u\"my mobile set has only one language, hence such replies\", \"\"),\n",
    "    (u\"थोड़ी\", \"\"),  # a little\n",
    "    (u\"थोड़ी\", \"\"),  # a little\n",
    "    (u\"(no script for kashmiri)\", \"\"),\n",
    "    (u\"less fluently\", \"\"),\n",
    "    (u\"некоторые славянские\", \"\"),\n",
    "    (u\"most of latin-based\", \"\"),\n",
    "    (u\"(i.e. scandinavian)\", \"\"),\n",
    "    (u\"но весьма прилично\", \"\"),\n",
    "    (u\"; не идеально\", \"\"),\n",
    "    (u\"will see\", \"\"),\n",
    "    (u\"языках\", \"\"),  # languages\n",
    "    (u\"язык\", \"\"),  # a language\n",
    "    (u\"на \", \"\"),  # on\n",
    "    (u\"basic\", \"\"),\n",
    "    (u\"none\", \"\"),\n",
    "    (u\"भाषा\", \"\"),  # language\n",
    "    (u\"लिपीके\", \"\"),  # script\n",
    "    (u\"सब\", \"\"),  # all\n",
    "    (u\"на своем есть жи\", \"russian\"),  # on its own?\n",
    "\n",
    "    # correction for misaligned data\n",
    "    (u\"1\", \"\"),\n",
    "    (u\"2\", \"\"),\n",
    "    (u\"3\", \"\"),\n",
    "    (u\"4\", \"\"),\n",
    "\n",
    "    (u\"first language is russian but i'm more fluent in english\", \"russian,english\"),\n",
    "    (u\"serbian (latin and cyrillic)\", \"serbian\"),\n",
    "    (u\"chinese (simplified)\", \"chinese-simplified\"),\n",
    "    (u\"chinese (mandarin)\", \"chinese-mandarin\"),\n",
    "    (u\"spanish (mexican)\", \"spanish-mexican\"),\n",
    "    (u\"scottish gaelic\", \"scottish-gaelic\"),\n",
    "    (u\"(latin, greek?)\", \"latin,greek\"),\n",
    "    (u\"classical greek\", \"greek-classical\"),\n",
    "    (u\"serbo-croatian\", \"serbian,croatian\"),\n",
    "    (u\"português br\", \"portuguese-brasilian\"),\n",
    "    (u\"swiss german\", \"german-swiss\"),\n",
    "    (u\"swissgerman\", \"german-swiss\"),\n",
    "    (u\"german swiss\", \"german-swiss\"),\n",
    "    (u\"uk english\", \"english\"),\n",
    "    (u\"englush\", \"english\"),\n",
    "    (u\"французский\", \"french\"),\n",
    "    (u\"francais\", \"french\"),\n",
    "    (u\"français\", \"french\"),\n",
    "    (u\"belorussian\", \"belarusian\"),\n",
    "    (u\"белорусском\", \"belarusian\"),\n",
    "    (u\"белорусский\", \"belarusian\"),\n",
    "    (u\"итальянский\", \"italian\"),\n",
    "    (u\"netherlands\", \"dutch\"),\n",
    "    (u\"нидерландский\", \"dutch\"),\n",
    "    (u\"slovenština\", \"slovak\"),\n",
    "    (u\"белоруссий\", \"belarusian\"),\n",
    "    (u\"болгарский\", \"bulgarian\"),\n",
    "    (u\"укр\", \"ukrainian\"),\n",
    "    (u\"украинская\", \"ukrainian\"),\n",
    "    (u\"латинский\", \"latin\"),\n",
    "    (u\"англиский\", \"english\"),\n",
    "    (u\"российский\", \"russian\"),\n",
    "    (u\"кацапській\", \"russian\"),\n",
    "    (u\"русс\", \"russian\"),\n",
    "    (u\"русски\", \"russian\"),\n",
    "    (u\"руссский\", \"russian\"),\n",
    "    (u\"руском\", \"russian\"),\n",
    "    (u\"украинском\", \"ukrainian\"),\n",
    "    (u\"лацiнка\", \"latin\"),\n",
    "    (u\"итальянсктй\", \"italian\"),\n",
    "    (u\"русским\", \"russian\"),\n",
    "    (u\"italiano\", \"italian\"),\n",
    "    (u\"аеглийский\", \"english\"),\n",
    "    (u\"руссе\", \"russian\"),\n",
    "    (u\"українській\", \"ukrainian\"),\n",
    "    (u\"исландский\", \"icelandic\"),\n",
    "    (u\"украинский\", \"ukrainian\"),\n",
    "    (u\"українська\", \"ukrainian\"),\n",
    "    (u\"український\", \"ukrainian\"),\n",
    "    (u\"ураинский\", \"ukrainian\"),\n",
    "    (u\"англійська\", \"english\"),\n",
    "    (u\"венгерский\", \"hungarian\"),\n",
    "    (u\"angličtina\", \"english\"),\n",
    "    (u\"английский\", \"english\"),\n",
    "    (u\"англійський\", \"english\"),\n",
    "    (u\"беларуский\", \"belarusian\"),\n",
    "    (u\"белоруский\", \"belarusian\"),\n",
    "    (u\"беларускі\", \"belarusian\"),\n",
    "    (u\"білоруська\", \"belarusian\"),\n",
    "    (u\"английском\", \"english\"),\n",
    "    (u\"укаринский\", \"ukrainian\"),\n",
    "    (u\"български\", \"bulgarian\"),\n",
    "    (u\"латышский\", \"latvian\"),\n",
    "    (u\"узбекский\", \"uzbek\"),\n",
    "    (u\"norwegiam\", \"norwegian\"),\n",
    "    (u\"російська\", \"russian\"),\n",
    "    (u\"português\", \"portuguese\"),\n",
    "    (u\"cantonese\", \"chinese-cantonese\"),\n",
    "    (u\"slovensky\", \"slovak\"),\n",
    "    (u\"эстонский\", \"estonian\"),\n",
    "    (u\"slovakian\", \"slovak\"),\n",
    "    (u\"казахский\", \"kazakh\"),\n",
    "    (u\"корейский\", \"korean\"),\n",
    "    (u\"испанский\", \"spanish\"),\n",
    "    (u\"японский\", \"japanese\"),\n",
    "    (u\"сербский\", \"serbian\"),\n",
    "    (u\"rosyjski\", \"russian\"),\n",
    "    (u\"englisch\", \"english\"),\n",
    "    (u\"espanish\", \"spanish\"),\n",
    "    (u\"english\", \"english\"),\n",
    "    (u\"englich\", \"english\"),\n",
    "    (u\"русском\", \"russian\"),\n",
    "    (u\"російський\", \"russian\"),\n",
    "    (u\"русскій\", \"russian\"),\n",
    "    (u\"frysian\", \"frisian\"),\n",
    "    (u\"русский\", \"russian\"),\n",
    "    (u\"seedish\", \"swedish\"),\n",
    "    (u\"deutsch\", \"german\"),\n",
    "    (u\"немецкий\", \"german\"),\n",
    "    (u\"німецький\", \"german\"),\n",
    "    (u\"чешский\", \"czech\"),\n",
    "    (u\"čeština\", \"czech\"),\n",
    "    (u\"español\", \"spanish\"),\n",
    "    (u\"enflish\", \"english\"),\n",
    "    (u\"poland\", \"polish\"),\n",
    "    (u\"польский\", \"polish\"),\n",
    "    (u\"польском\", \"polish\"),\n",
    "    (u\"польський\", \"polish\"),\n",
    "    (u\"польська\", \"polish\"),\n",
    "    (u\"eglish\", \"english\"),\n",
    "    (u\"polski\", \"polish\"),\n",
    "    (u\"inglés\", \"english\"),\n",
    "    (u\"руский\", \"russian\"),\n",
    "    (u\"česky\", \"czech\"),\n",
    "    (u\"मराठी\", \"marathi\"),\n",
    "    (u\"иврит\", \"hebrew\"),\n",
    "    (u\"hindu\", \"hindi\"),\n",
    "    (u\"český\", \"czech\"),\n",
    "    (u\"dutcg\", \"dutch\"),\n",
    "    (u\"anglais\", \"english\"),\n",
    "    (u\"अँग्रेजी\", \"english\"),\n",
    "    (u\"अंग्रेज़ी\", \"english\"),\n",
    "    (u\"अंग्रेजी\", \"english\"),\n",
    "    (u\"अंग्रेज़ी\", \"english\"),\n",
    "    (u\"इंग्रजी\", \"english\"),\n",
    "    (u\"इंग्लिश\", \"english\"),\n",
    "    (u\"उर्दू\", \"urdu\"),\n",
    "    (u\"गुजराती\", \"gujarati\"),\n",
    "    (u\"गढ़वाली\", \"garhwali\"),\n",
    "    (u\"नेपाली\", \"nepali\"),\n",
    "    (u\"मलयालम\", \"malayalam\"),\n",
    "    (u\"मैथिली\", \"maithili\"),\n",
    "    (u\"संस्कृत\", \"sanskrit\"),\n",
    "    (u\"samskrita\", \"sanskrit\"),\n",
    "    (u\"ह8नदी\", \"hindi\"),\n",
    "    (u\"हिन्दि\", \"hindi\"),\n",
    "    (u\"हिन्दी\", \"hindi\"),\n",
    "    (u\"हिंदी\", \"hindi\"),\n",
    "    (u\"चीनी\", \"chinese\"),\n",
    "    (u\"maardwari\", \"marwari\"),\n",
    "    (u\"maarwadi\", \"marwari\"),\n",
    "    (u\"marwadi\", \"marwari\"),\n",
    "    (u\"मारवाड़ी\", \"marwari\"),\n",
    "    (u\"bangla\", \"bengali\"),\n",
    "    (u\"espagnol\", \"spanish\"),\n",
    "    (u\"sambalpuria\", \"sambalpuri\"),\n",
    "    (u\"samskrutham\", \"sanskrit\"),\n",
    "    (u\"angrezi\", \"english\"),\n",
    "    (u\"gujrathi\", \"gujarati\"),\n",
    "    (u\"gujrati\", \"gujarati\"),\n",
    "    (u\"hindhi\", \"hindi\"),\n",
    "    (u\"hinfi\", \"hindi\"),\n",
    "    (u\"तेलुगू।\", \"telugu\"),\n",
    "    (u\"తెలుగు\", \"telugu\"),\n",
    "    (u\"punjabi\", \"panjabi\"),\n",
    "    (u\"पंजाबी\", \"panjabi\"),\n",
    "    (u\"फ्रेंच\", \"french\"),\n",
    "    (u\"भोजपुरी\", \"bhojpuri\"),\n",
    "    (u\"असमिया\", \"assamese\"),\n",
    "    (u\"देवनागरी\", \"devanagari\"),\n",
    "    (u\"नेपाल\", \"nepali\"),\n",
    "    (u\"नेवारी\", \"newari\"),\n",
    "    (u\"बंगाली\", \"bengali\"),\n",
    "    (u\"बांग्ला\", \"bengali\"),\n",
    "    (u\"башкирский\", \"bashkir\"),\n",
    "    (u\"вьетнамский\", \"vietnamese\"),\n",
    "    (u\"греческий\", \"greek\"),\n",
    "    (u\"greek\", \"greek\"),\n",
    "    (u\"китайский\", \"chinese\"),\n",
    "    (u\"рюске\", \"russian\"),\n",
    "    (u\"татарский\", \"tatar\"),\n",
    "    (u\"финский\", \"finnish\"),\n",
    "    (u\"якутский\", \"yakut\"),\n",
    "    (u\"थमिल\", \"tamil\"),\n",
    "    (u\"грузинский\", \"georgian\"),\n",
    "    (u\"нидерландски\", \"dutch\"),\n",
    "    (u\"odia\", \"oriya\"),\n",
    "    (u\"kutchi\", \"kachchi\"),\n",
    "\n",
    "])\n",
    "# sort from longest to the shortest\n",
    "LANGS_CORRECTIONS_SEARCH_KEYS = list(reversed(sorted(LANGS_CORRECTIONS_SEARCH.keys(), key=len)))\n",
    "\n",
    "# initial names that are parts of final names should go here\n",
    "LANGS_CORRECTIONS_EXACT = {\n",
    "    # \"german-german-swiss\": \"german-swiss\", # fix\n",
    "    # \"german-swissgerman\": \"german-swiss\", # fix\n",
    "    \"swiss\": \"german-swiss\",\n",
    "    # \"chinese-chinese-mandarin\": \"chinese-mandarin\", # fix\n",
    "    \"mandarin\": \"chinese-mandarin\",\n",
    "    # \"indonesiann\": \"indonesian\", # fix\n",
    "    \"indonesia\": \"indonesian\",\n",
    "    \"greek\": \"greek-modern\",\n",
    "    \"hind\": \"hindi\",\n",
    "    \"ukr\": \"ukrainian\",\n",
    "    \"ang\": \"english\",\n",
    "    \"de\": \"german\",\n",
    "    \"en\": \"english\",\n",
    "    \"eng\": \"english\",\n",
    "    \"cs\": \"czech\",\n",
    "    \"cz\": \"czech\",\n",
    "    \"fr\": \"french\",\n",
    "    \"ru\": \"russian\",\n",
    "    u\"рб\": \"belarusian\",\n",
    "    \"-\": \"\",\n",
    "}\n",
    "\n",
    "\n",
    "def normalise_languages(langs_series):\n",
    "    \"\"\"\n",
    "    Cleanup and normalise languages input from the forms.\n",
    "    \"\"\"\n",
    "\n",
    "    langs_series_out = []\n",
    "    for s in langs_series:\n",
    "        s = s.lower()\n",
    "        # apply search & replace corrections\n",
    "        for o in LANGS_CORRECTIONS_SEARCH_KEYS:\n",
    "            s = s.replace(o, LANGS_CORRECTIONS_SEARCH[o])\n",
    "        # remove punctuation\n",
    "        for x in PUNCTUATION:\n",
    "            s = s.replace(x, \",\")\n",
    "        # s = s.replace(u\" и \", \",\").replace(u\" and \", \",\").replace(\"&\", \",\").replace(\"/\", \",\").replace(\" \", \",\").replace(\".\", \",\")\n",
    "\n",
    "        langs = []\n",
    "        for l in s.split(\",\"):\n",
    "            ln = l.strip()\n",
    "            # apply exact corrections\n",
    "            if ln in LANGS_CORRECTIONS_EXACT:\n",
    "                ln = LANGS_CORRECTIONS_EXACT[ln]\n",
    "            if ln and ln != \"\" and ln != \"none\" and ln not in ANDS:\n",
    "                langs.append(ln)\n",
    "\n",
    "        if langs != []:\n",
    "            langs_series_out.append(\",\".join(list(set(langs))))\n",
    "        else:\n",
    "            langs_series_out.append(\"none\")\n",
    "    return Series(langs_series_out)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# For checking language names against ISO-639-3\n",
    "\n",
    "def import_iso_639_3():\n",
    "    \"\"\"\n",
    "    Import ISO 639-3 languages\n",
    "    \"\"\"\n",
    "\n",
    "    isopath = os.path.join(\"raw_data\", \"iso-639-3.xml\")\n",
    "    isotree = ET.parse(isopath)\n",
    "    language_names = []\n",
    "    for lang in isotree.getroot():\n",
    "        language_names.append(lang.attrib[\"name\"])\n",
    "    return language_names\n",
    "\n",
    "\n",
    "EXPECTED_LANGUAGES = [ln.lower() for ln in import_iso_639_3()] + [\"chinese-cantonese\", \"chinese-mandarin\", \"chinese-simplified\", \"german-swiss\", \"greek-modern\", \"greek-classical\", \"portuguese-brasilian\", \"scottish-gaelic\", \"spanish-mexican\", \"bahasa\", \"creole\", \"frisian\", \"hokkien\", \"devanagari\", \"gurmukhi\", \"none\"]  # adding some exceptions\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Mapping languages to corresponding scripts\n",
    "\n",
    "SCRIPT_LANGUAGES = {\n",
    "    \"latin\": [\"german\", \"galician\", \"polish\", \"icelandic\", \"turkish\", \"german-swiss\", \"hungarian\", \"catalan\", \"finnish\", \"serbian\", \"croatian\", \"portuguese\", \"czech\", \"estonian\", \"dutch\", \"faroese\", \"creole\", \"latin\", \"portuguese-brasilian\", \"french\", \"afrikaans\", \"uzbek\", \"vietnamese\", \"italian\", \"tatar\", \"slovak\", \"spanish\", \"spanish-mexican\", \"danish\", \"scottish-gaelic\", \"irish\", \"swedish\", \"slovenian\", \"latvian\", \"welsh\", \"lithuanian\", \"norwegian\", \"english\", \"frisian\", \"indonesian\", \"bahasa\", \"bosnian\", \"malay\"],\n",
    "    \"cyrillic\": [\"belarusian\", \"yakut\", \"macedonian\", \"serbian\", \"bashkir\", \"uzbek\", \"tatar\", \"bulgarian\", \"ukrainian\", \"kazakh\", \"bosnian\", \"russian\"],\n",
    "    \"devanagari\": [\"sanskrit\", \"devanagari\", \"hindi\", \"konkani\", \"sindhi\", \"rajasthani\", \"marathi\", \"newari\", \"marwari\", \"maithili\", \"bhojpuri\", \"garhwali\", \"kashmiri\", \"nepali\"],\n",
    "    \"other\": [\"urdu\", \"persian\", \"arabic\", \"chinese-cantonese\", \"hokkien\", \"chinese\", \"chinese-mandarin\", \"chinese-simplified\", \"greek-classical\", \"greek-modern\", \"kachchi\", \"gujarati\", \"oriya\", \"sambalpuri\", \"telugu\", \"panjabi\", \"gurmukhi\", \"bengali\", \"assamese\", \"japanese\", \"javanese\", \"armenian\", \"georgian\", \"tamil\", \"none\", \"tagalog\", \"malayalam\", \"kannada\", \"syriac\", \"hebrew\", \"korean\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame columns:\n",
    "CONTROL_COLUMNS = [\"date\", \"native languages\", \"fluent languages\", \"age\", \"reading skills\", \"design skills\",\n",
    "                   \"order\", \"typeface\", \"script\"]\n",
    "IGNORE_COLUMNS = [\"ip_address\", \"id\", \"form_id\", \"spam\", \"unnamed: 0\", \"email\", \"unnamed: 0.1\"]\n",
    "SCRIPT_TAG = {\"devanagari\": \"deva\", \"cyrillic\": \"cyrl\", \"latin\": \"latn\"}\n",
    "\n",
    "\n",
    "def readTriplets(path):\n",
    "    \"\"\"\n",
    "    Read triplets and responses from CSV & XLSX exported\n",
    "    from GetForm and FormKeep (manually editted).\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        logging.error(\"File does not exist\")\n",
    "    if os.path.isfile(path):\n",
    "        logging.info(\"Reading data from: %s\" % path)\n",
    "        if path.endswith(\"csv\"):\n",
    "            data = pd.read_csv(path, encoding=\"utf-8\")\n",
    "        elif path.endswith(\"xls\") or path.endswith(\"xlsx\"):\n",
    "            data = pd.read_excel(path)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # make multiindex for columns and fix small things\n",
    "        columns = []\n",
    "        for c in data.columns:\n",
    "            c = c.lower()\n",
    "            if c in IGNORE_COLUMNS:\n",
    "                columns.append((\"ignore\", \"ignore\", c))\n",
    "            elif c in CONTROL_COLUMNS:\n",
    "                columns.append((\"control\", \"control\", c))\n",
    "            elif c.startswith(\"order\"):\n",
    "                columns.append((\"ignore\", \"ignore\", c))\n",
    "            else:\n",
    "                # fix column names for Cyrillic characters\n",
    "                c = c.replace(\"short-i\", \"short i\").replace(\"hard-sign\", \"hard sign\").replace(\"soft-sign\", \"soft sign\").lower()\n",
    "                typeface, script, triplet = c.split(\"_\")\n",
    "                # normalize typeface names\n",
    "                typeface = typeface.replace(\" \", \"-\").lower()\n",
    "                script = script.lower()\n",
    "                chars = triplet.split(\"-\")\n",
    "                if script == \"devanagari\":\n",
    "                    # capitalize devanagari character names\n",
    "                    chars = [SCRIPT_TAG[script]+\".\"+char.capitalize() for char in chars]\n",
    "                else:\n",
    "                    # remove spaces from two-word character names\n",
    "                    chars = [SCRIPT_TAG[script]+\".\"+char.replace(\" \", \"-\") for char in chars]\n",
    "                triplet = str(sorted(chars))\n",
    "                columns.append((script, typeface, triplet))\n",
    "        columns = pd.MultiIndex.from_tuples(columns, names=[\"script\", \"typeface\", \"triplet\"])\n",
    "        data.columns = columns\n",
    "        data[\"control\", \"control\", \"order\"] = \"\"\n",
    "        data[\"control\", \"control\", \"script\"] = \"\"\n",
    "        data[\"control\", \"control\", \"typeface\"] = \"\"\n",
    "\n",
    "        for i, _ in data.iterrows():\n",
    "            for c in data.loc[i].index:\n",
    "                if c[0] not in [\"control\", \"ignore\"] and c[2] not in [\"control\", \"ignore\"] and pd.notnull(data.loc[i][c]):\n",
    "                    script = c[0]\n",
    "                    typeface = c[1]\n",
    "                    data.at[i, (\"control\", \"control\", \"script\")] = script\n",
    "                    data.at[i, (\"control\", \"control\", \"typeface\")] = typeface\n",
    "            for c in data.loc[i].index:\n",
    "                if c[2] in IGNORE_COLUMNS or c[2] in CONTROL_COLUMNS:\n",
    "                    pass\n",
    "                elif c[2].startswith(\"order\") and pd.notnull(data.loc[i][c]):\n",
    "                    data.at[i, (\"control\", \"control\", \"order\")] = int(data.loc[i][c])\n",
    "                elif pd.notnull(data.loc[i][c]):\n",
    "                    # prefix response\n",
    "                    if script == \"devanagari\":\n",
    "                        # capitalize devanagari character names\n",
    "                        data.at[i, c] = SCRIPT_TAG[script] + \".\" + data.loc[i][c].capitalize()\n",
    "                    else:\n",
    "                        data.at[i, c] = SCRIPT_TAG[script] + \".\" + data.loc[i][c]\n",
    "        logging.info(\"  -> importing %s values\" % len(data.index))\n",
    "        del data[\"ignore\"]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data from: raw_data/devanagari/itf-devanagari.xls\n",
      "  -> importing 36 values\n",
      "Reading data from: raw_data/devanagari/lohit.xls\n",
      "  -> importing 63 values\n",
      "Reading data from: raw_data/devanagari/kohinoor.xls\n",
      "  -> importing 36 values\n",
      "Reading data from: raw_data/devanagari/ek-mukta.xls\n",
      "  -> importing 58 values\n",
      "Reading data from: raw_data/devanagari/devanagari-mt.xls\n",
      "  -> importing 55 values\n",
      "Reading data from: raw_data/devanagari/adobe-devanagari.xls\n",
      "  -> importing 50 values\n",
      "Reading data from: raw_data/devanagari/murty-hindi.xls\n",
      "  -> importing 62 values\n",
      "Reading data from: raw_data/devanagari/nirmala-ui.xls\n",
      "  -> importing 51 values\n",
      "Reading data from: raw_data/devanagari/_devanagari_initial.xlsx\n",
      "  -> importing 42 values\n",
      "Reading data from: raw_data/cyrillic/arial.xls\n",
      "  -> importing 50 values\n",
      "Reading data from: raw_data/cyrillic/courier-new.xls\n",
      "  -> importing 44 values\n",
      "Reading data from: raw_data/cyrillic/verdana.xls\n",
      "  -> importing 45 values\n",
      "Reading data from: raw_data/cyrillic/georgia.xls\n",
      "  -> importing 50 values\n",
      "Reading data from: raw_data/cyrillic/century-schoolbook.xls\n",
      "  -> importing 43 values\n",
      "Reading data from: raw_data/cyrillic/times-new-roman.xls\n",
      "  -> importing 59 values\n",
      "Reading data from: raw_data/cyrillic/_cyrillic_initial_1_formkeep.xlsx\n",
      "  -> importing 28 values\n",
      "Reading data from: raw_data/cyrillic/pt-sans.xlsx\n",
      "  -> importing 39 values\n",
      "Reading data from: raw_data/cyrillic/_cyrillic_initial_2.xlsx\n",
      "  -> importing 10 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/pt-sans.csv\n",
      "  -> importing 43 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/century-schoolbook.csv\n",
      "  -> importing 76 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/_latin_mix_from_getform.csv\n",
      "  -> importing 43 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/verdana.csv\n",
      "  -> importing 68 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/candara.xls\n",
      "  -> importing 61 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/cambria.xls\n",
      "  -> importing 74 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/arial.xls\n",
      "  -> importing 77 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/courier-new.xls\n",
      "  -> importing 108 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/pt-serif.xls\n",
      "  -> importing 78 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/calibri.xls\n",
      "  -> importing 77 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/futura.xls\n",
      "  -> importing 67 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/georgia.xls\n",
      "  -> importing 79 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/times-new-roman.xls\n",
      "  -> importing 64 values\n",
      "Reading data from: raw_data/latin_and_cyrillic/_latin_initial.xlsx\n",
      "  -> importing 52 values\n",
      "/var/folders/f2/mncm4dfn70gbl4mshhy77hbr0000gn/T/ipykernel_13860/1725517912.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_all[\"control\", \"control\", \"native in script\"] = False\n",
      "/var/folders/f2/mncm4dfn70gbl4mshhy77hbr0000gn/T/ipykernel_13860/1725517912.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_all[\"control\", \"control\", \"fluent in script\"] = False\n"
     ]
    }
   ],
   "source": [
    "# read triplets from all CSVs in the source folder\n",
    "data_all = []\n",
    "for path_pattern in LOAD_FROM:\n",
    "    for path in glob.glob(path_pattern):\n",
    "        data_all.append(readTriplets(path))\n",
    "data_all = pd.concat(data_all)\n",
    "data_all[\"control\", \"control\", \"native in script\"] = False\n",
    "data_all[\"control\", \"control\", \"fluent in script\"] = False\n",
    "data_all.reset_index(drop=True, inplace=True)\n",
    "data_all.index.name = \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving all data to: csv/raw-data-preprocessed.csv\n",
      "Saving the data to individual files.\n",
      "Statistics for typefaces and script (all/non-designers):\n",
      "Languages (new, unexpected languages):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chinese-chinese-chinese-chinese-chinese-chinese-chinese-chinese-chinese-chinese-chinese-cantonese\n",
      "—\n"
     ]
    }
   ],
   "source": [
    "# make a copy\n",
    "data = pd.DataFrame(data_all)\n",
    "\n",
    "# normalize language names\n",
    "\n",
    "data[\"control\", \"control\", \"native languages\"] = normalise_languages(data[\"control\", \"control\", \"native languages\"].astype(\"unicode\"))\n",
    "data[\"control\", \"control\", \"fluent languages\"] = normalise_languages(data[\"control\", \"control\", \"fluent languages\"].astype(\"unicode\"))\n",
    "\n",
    "# resolve script fluency and nativity\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    script = row[\"control\", \"control\", \"script\"]\n",
    "    # set True/False if native/fluent in the script of the study\n",
    "    native_in_script = False\n",
    "    fluent_in_script = False\n",
    "    for lang in row[\"control\", \"control\", \"native languages\"].split(\",\"):\n",
    "        if lang in SCRIPT_LANGUAGES[script]:\n",
    "            native_in_script = True\n",
    "            fluent_in_script = True  # if native then also fluent\n",
    "    for lang in row[\"control\", \"control\", \"fluent languages\"].split(\",\"):\n",
    "        if lang in SCRIPT_LANGUAGES[script]:\n",
    "            fluent_in_script = True\n",
    "    # set True/False if native/fluent in the script of the study\n",
    "    data.loc[i, (\"control\", \"control\", \"native in script\")] = native_in_script\n",
    "    data.loc[i, (\"control\", \"control\", \"fluent in script\")] = fluent_in_script\n",
    "\n",
    "# fix values in reading skills\n",
    "data[\"control\", \"control\", \"reading skills\"] = data[\"control\", \"control\", \"reading skills\"].str.replace(\"_\", \" \")\n",
    "# fix values in age\n",
    "# data[\"control\", \"control\", \"age\"] = data[\"control\", \"control\", \"age\"].str.replace(\"-\", \"-\") # en dash -> hyphen\n",
    "# remove illiterate participants\n",
    "data = data[(data[\"control\", \"control\", \"fluent languages\"] != \"none\") | (data[\"control\", \"control\", \"native languages\"] != \"none\")]\n",
    "\n",
    "# reorder columns\n",
    "cc = [col for col in data.columns if col[0] == \"control\"]\n",
    "ncc = [col for col in data.columns if col[0] != \"control\"]\n",
    "data = pd.DataFrame(data, columns=cc+ncc, index=data.index)\n",
    "\n",
    "# sort by date\n",
    "data.sort_values([(\"control\", \"control\", \"date\")], axis=0, inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save all to one file\n",
    "path = os.path.join(SAVE_TO, \"raw-data-preprocessed.csv\")\n",
    "data.to_csv(path, encoding=\"utf-8\")\n",
    "logging.info(\"Saving all data to: %s\" % path)\n",
    "logging.info(\"Saving the data to individual files.\")\n",
    "logging.info(\"Statistics for typefaces and script (all/non-designers):\")\n",
    "\n",
    "logging.info(\"Languages (new, unexpected languages):\")\n",
    "# get a list of all languages\n",
    "all_langs = list(data[\"control\", \"control\", \"native languages\"])+list(data[\"control\", \"control\", \"fluent languages\"])\n",
    "languages = list(set((\",\".join(all_langs)).split(\",\")))\n",
    "# print unexpected languages\n",
    "for lang in sorted(languages):\n",
    "    if lang not in EXPECTED_LANGUAGES:\n",
    "        print(lang)  # the printout looks nicer this way\n",
    "else:\n",
    "    print(\"—\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
